from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
from typing import List, Optional, Dict
import json

from app.models.models import ChatSession, ChatMessage
from app.services.ai_service import kimi_ai


class ChatService:
    def __init__(self, db: AsyncSession):
        self.db = db
        self.ai = kimi_ai
    
    async def create_session(self, project_id: int, session_type: str = "design_assistant") -> ChatSession:
        """Create a new chat session"""
        session = ChatSession(
            project_id=project_id,
            session_type=session_type
        )
        self.db.add(session)
        await self.db.flush()
        return session
    
    async def save_message(
        self, 
        session_id: int, 
        role: str, 
        content: str, 
        message_type: str = "text",
        metadata: Dict = None
    ) -> ChatMessage:
        """Save a message"""
        message = ChatMessage(
            session_id=session_id,
            role=role,
            content=content,
            message_type=message_type,
            metadata=metadata or {}
        )
        self.db.add(message)
        await self.db.flush()
        return message
    
    async def get_messages(
        self, 
        session_id: int, 
        skip: int = 0, 
        limit: int = 100
    ) -> List[ChatMessage]:
        """Get chat history"""
        result = await self.db.execute(
            select(ChatMessage)
            .where(ChatMessage.session_id == session_id)
            .order_by(ChatMessage.created_at)
            .offset(skip)
            .limit(limit)
        )
        return result.scalars().all()
    
    async def get_ai_response(self, session_id: int, user_message: str) -> Dict:
        """Get AI response using Kimi"""
        try:
            # Build context from chat history
            chat_history = await self.get_messages(session_id, limit=10)
            messages = []
            
            # System prompt
            messages.append({
                "role": "system",
                "content": """ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å®¤å†…è®¾è®¡å¸ˆåŠ©æ‰‹ï¼Œæ“…é•¿ï¼š
1. æ ¹æ®ç”¨æˆ·éœ€æ±‚æ¨èè£…ä¿®é£æ ¼
2. æä¾›ææ–™é€‰æ‹©å»ºè®®
3. è§£ç­”è£…ä¿®ç›¸å…³é—®é¢˜
4. åˆ†ææˆ·å‹è®¾è®¡

è¯·ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„è¯­è¨€å›ç­”ï¼Œå¿…è¦æ—¶ç»™å‡ºå…·ä½“å»ºè®®å’Œæ•°æ®æ”¯æŒã€‚
å¦‚æœæ˜¯é£æ ¼æ¨èï¼Œè¯·ä»¥ç»“æ„åŒ–æ–¹å¼è¾“å‡ºä¾¿äºå‰ç«¯å±•ç¤ºã€‚"""
            })
            
            # Add chat history
            for msg in chat_history:
                messages.append({
                    "role": msg.role,
                    "content": msg.content
                })
            
            # Add current message
            messages.append({"role": "user", "content": user_message})
            
            # Call Kimi
            response = await self.ai.chat_completion(messages, temperature=0.8)
            content = response["choices"][0]["message"]["content"]
            
            # Determine message type based on content
            message_type = "text"
            metadata = {}
            
            # Check if response contains structured data
            if any(keyword in user_message for keyword in ["é£æ ¼", "æ¨è", "é€‚åˆ"]):
                message_type = "suggestion"
                # Try to parse structured recommendations
                try:
                    if "```json" in content:
                        json_str = content.split("```json")[1].split("```")[0].strip()
                        metadata = json.loads(json_str)
                except:
                    pass
            elif any(keyword in user_message for keyword in ["ææ–™", "åœ°æ¿", "ç“·ç –", "ä»·æ ¼"]):
                message_type = "material_suggestion"
            elif "?" in user_message or "ï¼Ÿ" in user_message:
                message_type = "answer"
            
            return {
                "content": content,
                "message_type": message_type,
                "metadata": metadata
            }
            
        except Exception as e:
            # Fallback to mock response if AI fails
            return await self._get_mock_response(user_message)
    
    async def _get_mock_response(self, user_message: str) -> Dict:
        """Fallback mock response"""
        user_lower = user_message.lower()
        
        if any(word in user_lower for word in ["é£æ ¼", "style", "è£…ä¿®"]):
            return {
                "content": "æ ¹æ®æ‚¨çš„æˆ·å‹å’Œå®¶åº­æƒ…å†µï¼Œæˆ‘æ¨èä»¥ä¸‹å‡ ç§é£æ ¼ä¾›æ‚¨å‚è€ƒï¼š\n\n1. **ç°ä»£ç®€çº¦** - ç®€æ´çº¿æ¡ï¼ŒåŠŸèƒ½è‡³ä¸Š\n2. **åŒ—æ¬§é£** - è‡ªç„¶æè´¨ï¼Œæ˜äº®æ¸©é¦¨\n3. **æ–°ä¸­å¼** - ä¼ ç»Ÿä¸ç°ä»£ç»“åˆ",
                "message_type": "suggestion",
                "metadata": {
                    "suggestions": [
                        {"id": "modern", "name": "ç°ä»£ç®€çº¦", "description": "ç®€æ´çº¿æ¡ï¼ŒåŠŸèƒ½è‡³ä¸Š"},
                        {"id": "nordic", "name": "åŒ—æ¬§é£", "description": "è‡ªç„¶æè´¨ï¼Œæ˜äº®æ¸©é¦¨"},
                        {"id": "chinese", "name": "æ–°ä¸­å¼", "description": "ä¼ ç»Ÿä¸ç°ä»£ç»“åˆ"}
                    ]
                }
            }
        
        elif any(word in user_lower for word in ["é¢„ç®—", "budget", "ä»·æ ¼", "å¤šå°‘é’±"]):
            return {
                "content": "è£…ä¿®é¢„ç®—é€šå¸¸åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªæ¡£æ¬¡ï¼š\n\n- **ç»æµå‹**ï¼š1000-1500å…ƒ/ã¡\n- **èˆ’é€‚å‹**ï¼š1500-2500å…ƒ/ã¡\n- **è±ªåå‹**ï¼š2500-4000å…ƒ/ã¡",
                "message_type": "suggestion"
            }
        
        return {
            "content": "æˆ‘ç†è§£æ‚¨çš„éœ€æ±‚ã€‚ä¸ºäº†æ›´å¥½åœ°ä¸ºæ‚¨è®¾è®¡ï¼Œèƒ½å¦å‘Šè¯‰æˆ‘æ›´å¤šä¿¡æ¯ï¼Ÿæ¯”å¦‚æ‚¨å®¶æœ‰å‡ å£äººã€æœ‰æ²¡æœ‰å® ç‰©ã€å–œæ¬¢æ˜äº®è¿˜æ˜¯æ¸©é¦¨çš„æ°›å›´ï¼Ÿ",
            "message_type": "question"
        }
    
    async def analyze_user_preferences(self, preferences: Dict) -> Dict:
        """Analyze user preferences using Kimi AI"""
        return await self.ai.analyze_style_preferences(preferences)
    
    async def process_quiz_answer(self, session_id: int, answer: Dict) -> Dict:
        """Process quiz answer and return next question or result"""
        current_step = answer.get("step", 1)
        selected_option = answer.get("option")
        
        # Save answer
        await self.save_message(
            session_id,
            "user",
            f"é€‰æ‹©äº†: {selected_option}",
            "quiz_answer",
            {"step": current_step, "answer": selected_option}
        )
        
        # Quiz flow
        if current_step == 1:
            return {
                "content": "å¥½çš„ï¼æ¥ä¸‹æ¥ï¼Œæ‚¨çš„å®¶åº­æˆå‘˜æ„æˆæ˜¯ï¼Ÿ",
                "message_type": "quiz",
                "metadata": {
                    "step": 2,
                    "suggestions": [
                        {"id": "couple", "text": "ğŸ’‘ æ–°å©šå¤«å¦»/æƒ…ä¾£", "icon": "ğŸ’‘"},
                        {"id": "family3", "text": "ğŸ‘¨â€ğŸ‘©â€ğŸ‘¦ ä¸‰å£ä¹‹å®¶", "icon": "ğŸ‘¨â€ğŸ‘©â€ğŸ‘¦"},
                        {"id": "family4", "text": "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ å››å£ä¹‹å®¶åŠä»¥ä¸Š", "icon": "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦"},
                        {"id": "multigen", "text": "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ğŸ‘´ğŸ‘µ ä¸‰ä»£åŒå ‚", "icon": "ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ğŸ‘´ğŸ‘µ"}
                    ]
                }
            }
        
        elif current_step == 2:
            return {
                "content": "å®¶é‡Œæœ‰å…»å® ç‰©å—ï¼Ÿ",
                "message_type": "quiz",
                "metadata": {
                    "step": 3,
                    "suggestions": [
                        {"id": "dog", "text": "ğŸ• æœ‰ç‹—ç‹—", "icon": "ğŸ•"},
                        {"id": "cat", "text": "ğŸˆ æœ‰çŒ«å’ª", "icon": "ğŸˆ"},
                        {"id": "other", "text": "ğŸ  å…¶ä»–å® ç‰©", "icon": "ğŸ "},
                        {"id": "none", "text": "ğŸš« æ²¡æœ‰å® ç‰©", "icon": "ğŸš«"}
                    ]
                }
            }
        
        elif current_step == 3:
            return {
                "content": "æ‚¨å¯¹æ”¶çº³ç©ºé—´çš„éœ€æ±‚ç¨‹åº¦ï¼Ÿ",
                "message_type": "quiz",
                "metadata": {
                    "step": 4,
                    "suggestions": [
                        {"id": "minimal", "text": "ğŸ“¦ æ–­èˆç¦»ï¼Œä¸œè¥¿å°‘", "icon": "ğŸ“¦"},
                        {"id": "normal", "text": "ğŸ—„ï¸ æ™®é€šéœ€æ±‚", "icon": "ğŸ—„ï¸"},
                        {"id": "lots", "text": "ğŸ“š ç‰©å“è¾ƒå¤šï¼Œéœ€è¦å¤§é‡æ”¶çº³", "icon": "ğŸ“š"},
                        {"id": "hoarder", "text": "ğŸšï¸ å›¤è´§çˆ±å¥½è€…", "icon": "ğŸšï¸"}
                    ]
                }
            }
        
        elif current_step == 4:
            # Use Kimi to generate personalized recommendation
            quiz_context = {
                "family_members": answer.get("family_members", 3),
                "has_pets": answer.get("has_pets", False),
                "storage_needs": answer.get("storage_needs", "normal"),
                "brightness_preference": answer.get("brightness", "bright")
            }
            
            # Get AI analysis
            ai_recommendation = await self.analyze_user_preferences(quiz_context)
            
            await self.save_message(
                session_id,
                "assistant",
                ai_recommendation.get("style_reasoning", ""),
                "quiz_result",
                ai_recommendation
            )
            
            styles = ai_recommendation.get("recommended_styles", ["ç°ä»£ç®€çº¦"])
            reasoning = ai_recommendation.get("style_reasoning", "æ ¹æ®æ‚¨çš„éœ€æ±‚æ¨è")
            
            return {
                "content": f"ğŸ‰ ä¸ºæ‚¨æ¨èï¼š**{' + '.join(styles)}**\n\n{reasoning}",
                "message_type": "quiz_result",
                "metadata": {
                    "result": ai_recommendation,
                    "next_action": "å¼€å§‹è®¾è®¡"
                }
            }
        
        return {"error": "Invalid quiz step"}